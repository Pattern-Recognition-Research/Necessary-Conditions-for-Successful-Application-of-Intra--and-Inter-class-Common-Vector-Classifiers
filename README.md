# Necessary-Conditions-for-Successful-Application-of-Intra--and-Inter-class-Common-Vector-Classifiers

In this study, classification performances and inherent characteristics of two variations of the common vector approach (CVA), namely the mutual CVA and the discriminative CVA (DCVA), are investigated, especially for images that contain a shared background, including binary images. Although recent papers mainly emphasize the superiority of DCVA as the preferred subspace method over certain examples, two major risks are investigated in this work. The first risk case emerges when the dimension of the feature vector falls below the number of training samples, which easily occurs with the discriminative methods. Besides, it was observed that data augmentation using additional concatenation of fixed backgrounds does not help DCVA for this problem, either. The second case was observed particularly during the classification of binary images, where CVA outperforms its discriminative version. Although CVA and DCVA are well-known methods, the experimental results indicate that their application needs careful consideration of training data size. Once the necessary attention is paid, CVA is capable of outperforming many classifiers, including support vector machines (SVM). This study puts an assessment of conditions on CVA variants for their successful application in image classification
